<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Nodestream Blog</title>
        <link>https://nodestream-proj.github.io/docs/blog</link>
        <description>Nodestream Blog</description>
        <lastBuildDate>Mon, 24 Feb 2025 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Nodestream 0.14 Release]]></title>
            <link>https://nodestream-proj.github.io/docs/blog/2025/02/24/nodestream-0-14</link>
            <guid>https://nodestream-proj.github.io/docs/blog/2025/02/24/nodestream-0-14</guid>
            <pubDate>Mon, 24 Feb 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[We are happy to announce the release of Nodestream 0.14.]]></description>
            <content:encoded><![CDATA[<p>We are happy to announce the release of Nodestream 0.14.
This release includes a number of new features and improvements.
However, its breaking changes are minimal, so upgrading should be a breeze.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="breaking-changes">Breaking Changes<a href="https://nodestream-proj.github.io/docs/blog/2025/02/24/nodestream-0-14#breaking-changes" class="hash-link" aria-label="Direct link to Breaking Changes" title="Direct link to Breaking Changes">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="file-extractors">File Extractors<a href="https://nodestream-proj.github.io/docs/blog/2025/02/24/nodestream-0-14#file-extractors" class="hash-link" aria-label="Direct link to File Extractors" title="Direct link to File Extractors">​</a></h3>
<p>In <code>0.13</code>, we introduced a united file handling extractor. However, we kept the old extractors around for backwards compatibility.
Starting with this release, we have removed the old extractors and everything is now handled by
the <code>UnifiedFileExtractor</code> extractor which is now renamed to <code>FileExtractor</code>.</p>
<p><strong>Check out the docs on it <a href="https://nodestream-proj.github.io/docs/docs/reference/extractors/#the-file-extractor">here</a></strong>.</p>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
<li><a href="https://github.com/angelosantos4" target="_blank" rel="noopener noreferrer">Angelo Santos</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-features">New Features<a href="https://nodestream-proj.github.io/docs/blog/2025/02/24/nodestream-0-14#new-features" class="hash-link" aria-label="Direct link to New Features" title="Direct link to New Features">​</a></h2>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="object-storage-apis">Object Storage APIs<a href="https://nodestream-proj.github.io/docs/blog/2025/02/24/nodestream-0-14#object-storage-apis" class="hash-link" aria-label="Direct link to Object Storage APIs" title="Direct link to Object Storage APIs">​</a></h2>
<p>Nodestream now has a new object storage abstraction.
These APIs allow steps in your pipeline to interact with object storage to persist data between executions.
We see incredible value in this feature as it allows for more complex pipelines to be built.
We've implemented serveral features in this relase that leverage this new abstraction.</p>
<p>You can persist objects locally or in the cloud via AWS S3.
Like large amounts of the framework it is plubbable and can be extended to support other object storage providers.</p>
<p><strong>Check out the docs on it <a href="https://nodestream-proj.github.io/docs/docs/reference/object-storage/">here</a></strong>.</p>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
<li><a href="https://github.com/angelosantos4" target="_blank" rel="noopener noreferrer">Angelo Santos</a></li>
<li><a href="https://github.com/ccloes" target="_blank" rel="noopener noreferrer">Chad Cloes</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="extractor-checkpointing">Extractor Checkpointing<a href="https://nodestream-proj.github.io/docs/blog/2025/02/24/nodestream-0-14#extractor-checkpointing" class="hash-link" aria-label="Direct link to Extractor Checkpointing" title="Direct link to Extractor Checkpointing">​</a></h2>
<p>Previously, extractors would always start from the beginning of their data source.
If a pipeline crashed or was interrupted, the extractor would start from the beginning of the data source again.
This lead to duplicate data being extracted, processed, and inserted into the database.</p>
<p>Now with nodestream 0.14, extractors can now checkpoint their progress.
This means that if a pipeline crashes or is interrupted, the extractor will be start from where it left off.
To do this, the extractor will store a checkpoint via its object storage.
Therefore, in order to use this feature, you must have object storage configured during your pipeline execution.
Checkpoints are cleared when a pipeline is successfully completed.</p>
<p>Curious how to implement this for your extractor? We've update the tutorial on it <a href="https://nodestream-proj.github.io/docs/docs/tutorials-advanced/new-steps/#creating-an-extractor">here</a>.</p>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
<li><a href="https://github.com/angelosantos4" target="_blank" rel="noopener noreferrer">Angelo Santos</a></li>
<li><a href="https://github.com/ccloes" target="_blank" rel="noopener noreferrer">Chad Cloes</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="record-schema-enforcement">Record Schema Enforcement<a href="https://nodestream-proj.github.io/docs/blog/2025/02/24/nodestream-0-14#record-schema-enforcement" class="hash-link" aria-label="Direct link to Record Schema Enforcement" title="Direct link to Record Schema Enforcement">​</a></h2>
<p>Nodestream now has a new record schema enforcement feature.
Nodestream pipelines tend to be highly dependent on the schema of the data being processed.
Depending on the data source, the schema can change over time.
This can lead to pipelines failing or producing incorrect results.</p>
<p>With this new feature, you can now enforce a schema on your data.
This means that if the schema of the data changes, the pipeline will skip or warn about
the records that do not match the schema.</p>
<p>Not only that, but you can also use this feature to automatically infer the
schema of your data and then enforce it.</p>
<p><strong>Check out the docs on it <a href="https://nodestream-proj.github.io/docs/docs/reference/filters/">here</a></strong>.</p>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
<li><a href="https://github.com/angelosantos4" target="_blank" rel="noopener noreferrer">Angelo Santos</a></li>
<li><a href="https://github.com/ccloes" target="_blank" rel="noopener noreferrer">Chad Cloes</a></li>
</ul>]]></content:encoded>
            <category>release</category>
            <category>nodestream</category>
        </item>
        <item>
            <title><![CDATA[Nodestream 0.13 Release]]></title>
            <link>https://nodestream-proj.github.io/docs/blog/2024/08/09/nodestream-0-13</link>
            <guid>https://nodestream-proj.github.io/docs/blog/2024/08/09/nodestream-0-13</guid>
            <pubDate>Fri, 09 Aug 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[We are happy to announce the release of Nodestream 0.13.]]></description>
            <content:encoded><![CDATA[<p>We are happy to announce the release of Nodestream 0.13.
This release includes a number of new features and improvements.
However, its breaking changes are minimal, so upgrading should be a breeze.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="breaking-changes">Breaking Changes<a href="https://nodestream-proj.github.io/docs/blog/2024/08/09/nodestream-0-13#breaking-changes" class="hash-link" aria-label="Direct link to Breaking Changes" title="Direct link to Breaking Changes">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="unified-file-extractors">Unified File Extractors<a href="https://nodestream-proj.github.io/docs/blog/2024/08/09/nodestream-0-13#unified-file-extractors" class="hash-link" aria-label="Direct link to Unified File Extractors" title="Direct link to Unified File Extractors">​</a></h3>
<p>In the past, we had separate file extractors for local, remote, and S3 files.
This was a bit cumbersome for a couple of reasons:</p>
<ul>
<li>On the maintainability side, we had to make sure that all of these extractors were kept in sync with each other.</li>
<li>On the user side, it was limiting to have to choose between these extractors when the only difference was the location of the file.</li>
</ul>
<p>Starting with this release, we have unified these extractors into a single <code>UnifiedFileExtractor</code> extractor.
This extractor can handle local, remote, and S3 files (so functionality is not lost).</p>
<p><strong>Check out the docs on it <a href="https://nodestream-proj.github.io/docs/docs/reference/extractors/#the-file-extractor">here</a></strong>.</p>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
<li><a href="https://github.com/angelosantos4" target="_blank" rel="noopener noreferrer">Angelo Santos</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="changing-source-node-behavior-with-properties">Changing Source Node Behavior With <code>properties</code><a href="https://nodestream-proj.github.io/docs/blog/2024/08/09/nodestream-0-13#changing-source-node-behavior-with-properties" class="hash-link" aria-label="Direct link to changing-source-node-behavior-with-properties" title="Direct link to changing-source-node-behavior-with-properties">​</a></h3>
<p>In the past, the <code>properties</code> key automatically lower cased all string property values.
This was because there was one set of normalization rules for the entire source node interpretation.
However, this was a bit limiting because it was not possible to have different normalization rules for different properties.</p>
<p>Starting with this release, the <code>properties</code> key no longer automatically lower cases all string property values.
Instead, you can now define normalization rules for keys and properties separately (via the <code>key_normalization</code> and <code>property_normalization</code> properties).
However, if you specify the <code>normalization</code> key, it will apply to both keys and properties and will default to lower casing all string property values.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-features">New Features<a href="https://nodestream-proj.github.io/docs/blog/2024/08/09/nodestream-0-13#new-features" class="hash-link" aria-label="Direct link to New Features" title="Direct link to New Features">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="squashing-migrations">Squashing Migrations<a href="https://nodestream-proj.github.io/docs/blog/2024/08/09/nodestream-0-13#squashing-migrations" class="hash-link" aria-label="Direct link to Squashing Migrations" title="Direct link to Squashing Migrations">​</a></h3>
<p>In the past, migrations were applied one by one in order.
If during development, you were constantly iterating on a data model you could be constantly adding migrations.
This resulted in a lot of migrations being applied that were essentially intermediary when going to production.
As a result, the migration node count could get quite large with a lot of "messy" migrations.</p>
<p>Starting with this release, you can now squash migrations.
This means that you can take a set of migrations and squash them into a single, optimized set of migrations.
This can be useful for cleaning up the migration node count and making it easier to understand the data model.
Additionally, the old migrations are still stored in the project, so you can always go back to them if you need to.
If a database has partially applied a sequence of migrations that was squashed, we can't used the squashed migration.
Instead, the logic will fall back to the original migrations.</p>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
<li><a href="https://github.com/angelosantos4" target="_blank" rel="noopener noreferrer">Angelo Santos</a></li>
</ul>
<p><strong>Check out the docs on it <a href="https://nodestream-proj.github.io/docs/docs/tutorials-intermediate/working-with-migrations/#squash-migrations">here</a></strong>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="compressed-file-handling">Compressed File Handling<a href="https://nodestream-proj.github.io/docs/blog/2024/08/09/nodestream-0-13#compressed-file-handling" class="hash-link" aria-label="Direct link to Compressed File Handling" title="Direct link to Compressed File Handling">​</a></h3>
<p>Many users have data stored in compressed files.
This release adds support for compressed files that are <code>.gz</code>, <code>.bz2</code> in format.
This support is available in the <code>UnifiedFileExtractor</code> extractor.</p>
<p><strong>Check out the docs on it <a href="https://nodestream-proj.github.io/docs/docs/reference/extractors/#the-file-extractor">here</a></strong>.</p>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/grantleehoffman" target="_blank" rel="noopener noreferrer">Grant Hoffman</a></li>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="improved-llm-compatible-schema-printing">Improved LLM Compatible Schema Printing<a href="https://nodestream-proj.github.io/docs/blog/2024/08/09/nodestream-0-13#improved-llm-compatible-schema-printing" class="hash-link" aria-label="Direct link to Improved LLM Compatible Schema Printing" title="Direct link to Improved LLM Compatible Schema Printing">​</a></h3>
<p>The <code>llm</code> format is a format that is used to represent the schema of a graph.
This release adds improved support for printing the schema in a format that is compatible with an llm.</p>
<p>In short, it uses a cypher-esque syntax to represent the schema of the graph:</p>
<div class="language-cypher codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-cypher codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Node Types:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Person: first_name: STRING, last_name: STRING, last_ingested_at: DATETIME, age: STRING</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Number: number: STRING, last_ingested_at: DATETIME</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Relationship Types:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">KNOWS: last_ingested_at: DATETIME</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Adjancies:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(:Person)-[:KNOWS]-&gt;(:Person)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
<li><a href="https://github.com/angelosantos4" target="_blank" rel="noopener noreferrer">Angelo Santos</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="improved-error-messages-in-value-providers">Improved Error Messages in Value Providers<a href="https://nodestream-proj.github.io/docs/blog/2024/08/09/nodestream-0-13#improved-error-messages-in-value-providers" class="hash-link" aria-label="Direct link to Improved Error Messages in Value Providers" title="Direct link to Improved Error Messages in Value Providers">​</a></h3>
<p>Nodestream uses value providers to extract values from documents and map them to graph.
Every time you get an error in a value provider, it can be a bit tricky to debug.
This release adds improved error messages to value providers to make it easier to debug issues.</p>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/yasonk" target="_blank" rel="noopener noreferrer">Yason Khaburzaniya</a></li>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dynamodb-extractor">DynamoDB Extractor<a href="https://nodestream-proj.github.io/docs/blog/2024/08/09/nodestream-0-13#dynamodb-extractor" class="hash-link" aria-label="Direct link to DynamoDB Extractor" title="Direct link to DynamoDB Extractor">​</a></h3>
<p>DynamoDB is a popular NoSQL database that is used by many people to store data.
This release adds support for DynamoDB as a first class citizen via the <code>DynamoDBExtractor</code>.</p>
<p><strong>Check out the docs on it <a href="https://nodestream-proj.github.io/docs/docs/reference/extractors/#dynamodbextractor">here</a></strong>.</p>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/angelosantos4" target="_blank" rel="noopener noreferrer">Angelo Santos</a></li>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sqs-and-queue-extractor-support">SQS and Queue Extractor Support<a href="https://nodestream-proj.github.io/docs/blog/2024/08/09/nodestream-0-13#sqs-and-queue-extractor-support" class="hash-link" aria-label="Direct link to SQS and Queue Extractor Support" title="Direct link to SQS and Queue Extractor Support">​</a></h3>
<p>Many users have data stored in SQS and other queue services.
This release adds support for SQS and other queue services via the <code>QueueExtractor</code>.
Concecptually, this extractor is similar to the <code>StreamExtractor</code> but for queues.</p>
<p><strong>Check out the docs on it <a href="https://nodestream-proj.github.io/docs/docs/reference/extractors/#queueconnector">here</a></strong>.</p>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/grantleehoffman" target="_blank" rel="noopener noreferrer">Grant Hoffman</a></li>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="release-attestations">Release Attestations<a href="https://nodestream-proj.github.io/docs/blog/2024/08/09/nodestream-0-13#release-attestations" class="hash-link" aria-label="Direct link to Release Attestations" title="Direct link to Release Attestations">​</a></h3>
<p><code>0.13</code> marks the first release were nodestream and all of its dependencies are signed and attested to
via <a href="https://github.blog/news-insights/product-news/introducing-artifact-attestations-now-in-public-beta/" target="_blank" rel="noopener noreferrer">Github's Attestation support</a>. This means that you can be sure that the code you are running is the code that was intended to be run.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dependency-updates">Dependency Updates<a href="https://nodestream-proj.github.io/docs/blog/2024/08/09/nodestream-0-13#dependency-updates" class="hash-link" aria-label="Direct link to Dependency Updates" title="Direct link to Dependency Updates">​</a></h3>
<p>This release includes updates to dependencies to keep Nodestream up to date with the latest and greatest.
Some dependencies that were updated include:</p>
<ul>
<li><code>httpx</code> to <code>&gt;=0.27.0</code></li>
<li><code>uvloop</code> to <code>&gt;=0.17.0, &lt;=0.19.0</code> (Not installed/used on Python 3.13 due to compatibility issues)</li>
<li><code>numpy</code> to <code>&gt;=2.0.0</code></li>
<li><code>pyarrow</code> to <code>17.0.0</code></li>
<li><code>python</code> 3.13 has been added to the supported versions matrix.</li>
<li>A variety of other dependencies have had their supported versions widened to be more permissive.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes">Bug Fixes<a href="https://nodestream-proj.github.io/docs/blog/2024/08/09/nodestream-0-13#bug-fixes" class="hash-link" aria-label="Direct link to Bug Fixes" title="Direct link to Bug Fixes">​</a></h3>
<ul>
<li>Fixed a bug where schema inference was not working correctly in some cases (with switch interpretations).</li>
<li>Fixed a variety of bugs related to the pipeline runtime that were causing mishandled errors.</li>
</ul>]]></content:encoded>
            <category>release</category>
            <category>nodestream</category>
        </item>
        <item>
            <title><![CDATA[Migrations Design in Nodestream 0.12]]></title>
            <link>https://nodestream-proj.github.io/docs/blog/2024/05/14/migrations-evolution</link>
            <guid>https://nodestream-proj.github.io/docs/blog/2024/05/14/migrations-evolution</guid>
            <pubDate>Tue, 14 May 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[In the release notes for Nodestream 0.12, we mentioned that we had added support for migrations.]]></description>
            <content:encoded><![CDATA[<p>In the release notes for Nodestream 0.12, we mentioned that we had added support for migrations.
This is a feature that we have been wanting to add for a long time, and we are excited to finally have it in place.
In this post, we will discuss what migrations are, why they are important, and how they work in Nodestream.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="evolutionary-database-design">Evolutionary Database Design<a href="https://nodestream-proj.github.io/docs/blog/2024/05/14/migrations-evolution#evolutionary-database-design" class="hash-link" aria-label="Direct link to Evolutionary Database Design" title="Direct link to Evolutionary Database Design">​</a></h2>
<p>Evolutionary database design is the idea that the database schema should evolve over time as the application changes.
This is in contrast to the traditional approach of creating a fixed schema at the beginning of a project and then never changing it.
With evolutionary database design, the schema is treated as a living document that can be updated and modified as needed.
If you want to go deep into this topic, we recommend reading the <a href="https://martinfowler.com/articles/evodb.html" target="_blank" rel="noopener noreferrer">Martin Fowler's page</a> on the subject.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-migrations">Why Migrations?<a href="https://nodestream-proj.github.io/docs/blog/2024/05/14/migrations-evolution#why-migrations" class="hash-link" aria-label="Direct link to Why Migrations?" title="Direct link to Why Migrations?">​</a></h2>
<p>Migrations are a way to manage the evolution of the database schema in a controlled and repeatable way.
They allow you to define the changes that need to be made to the schema in a series of files that can be run in sequence.
This makes it easy to track changes to the schema over time and to apply those changes to multiple environments, such as development, staging, and production.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="surveying-all-the-types-of-schema-changes">Surveying All The Types of Schema Changes<a href="https://nodestream-proj.github.io/docs/blog/2024/05/14/migrations-evolution#surveying-all-the-types-of-schema-changes" class="hash-link" aria-label="Direct link to Surveying All The Types of Schema Changes" title="Direct link to Surveying All The Types of Schema Changes">​</a></h2>
<p>Graph databases are schema-less, but the data model is still defined by the relationships between nodes and edges and the properties of those nodes and edges.
This means that there is still a schema to manage, even if it is not as rigid as a traditional relational database schema.
Since nodestream is agnostic to the underlying database, we need to be able to support migrations for all types of databases that nodestream can work with.
Therefore we need to support migrations that are designed against an abstract graph model and leave the implementation details to the specific database connector.
So lets examine the types of schema changes that can exist in a graph database:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="creating-new-nodes-and-edges-types">Creating New Nodes and Edges Types<a href="https://nodestream-proj.github.io/docs/blog/2024/05/14/migrations-evolution#creating-new-nodes-and-edges-types" class="hash-link" aria-label="Direct link to Creating New Nodes and Edges Types" title="Direct link to Creating New Nodes and Edges Types">​</a></h3>
<p>The most basic type of schema change is creating new node and edge types.
This is equivalent to creating a new table in a relational database.
When you create a new node or edge type, you may need to define the properties that it will have and the relationships that it will have with other nodes and edges.</p>
<p>Depending on the underlying database, this might involve creating a new index or constraint to enforce the uniqueness of the new node or edge type.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="removing-nodes-and-edges-types">Removing Nodes and Edges Types<a href="https://nodestream-proj.github.io/docs/blog/2024/05/14/migrations-evolution#removing-nodes-and-edges-types" class="hash-link" aria-label="Direct link to Removing Nodes and Edges Types" title="Direct link to Removing Nodes and Edges Types">​</a></h3>
<p>Conversely, you may also need to remove existing node and edge types.
This is equivalent to dropping a table in a relational database.
Most graph databases do not support leaving orphaned nodes or edges, so you may need to delete all nodes and edges of the type that you are removing.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="adding-properties-to-nodes-and-edges">Adding Properties to Nodes and Edges<a href="https://nodestream-proj.github.io/docs/blog/2024/05/14/migrations-evolution#adding-properties-to-nodes-and-edges" class="hash-link" aria-label="Direct link to Adding Properties to Nodes and Edges" title="Direct link to Adding Properties to Nodes and Edges">​</a></h3>
<p>Another common type of schema change is adding properties to existing nodes and edges.
This is equivalent to adding a new column to a table in a relational database.
When you add a property to a node or edge, you may need to define a default value for that property or update existing nodes and edges to have a value for that property.</p>
<p>One tricky case is when you add a property that is part of the nodes or edges key.
In this case, you may need to update the key of the node or edge to include the new property.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="removing-properties-from-nodes-and-edges">Removing Properties from Nodes and Edges<a href="https://nodestream-proj.github.io/docs/blog/2024/05/14/migrations-evolution#removing-properties-from-nodes-and-edges" class="hash-link" aria-label="Direct link to Removing Properties from Nodes and Edges" title="Direct link to Removing Properties from Nodes and Edges">​</a></h3>
<p>Conversely, you may also need to remove properties from existing nodes and edges.
This is equivalent to dropping a column from a table in a relational database.
When you remove a property from a node or edge, you may need to update existing nodes and edges to remove the value for that property.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="adding-and-removing-indexes">Adding and Removing Indexes<a href="https://nodestream-proj.github.io/docs/blog/2024/05/14/migrations-evolution#adding-and-removing-indexes" class="hash-link" aria-label="Direct link to Adding and Removing Indexes" title="Direct link to Adding and Removing Indexes">​</a></h3>
<p>Another common type of schema change is adding and removing indexes.
Indexes are used to speed up queries by allowing the database to quickly find nodes and edges that match certain criteria.
When you add an index, you may need to define the properties that the index will be based on and the type of index that will be used.
When you remove an index, you may need to update existing indexes to remove the properties that the index was based on.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="topological-changes">Topological Changes<a href="https://nodestream-proj.github.io/docs/blog/2024/05/14/migrations-evolution#topological-changes" class="hash-link" aria-label="Direct link to Topological Changes" title="Direct link to Topological Changes">​</a></h3>
<p>Finally, you may need to make topological changes to the schema such as adding or removing relationships between nodes and edges.
This is equivalent to adding or removing foreign keys in a relational database.</p>
<p>When you change the adjancency of nodes and edges, you may want to clean up the data to ensure that it is consistent with the new schema.
This may involve updating existing nodes and edges to reflect the new relationships or deleting nodes and edges that are no longer needed.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-migrations-work-in-nodestream">How Migrations Work in Nodestream<a href="https://nodestream-proj.github.io/docs/blog/2024/05/14/migrations-evolution#how-migrations-work-in-nodestream" class="hash-link" aria-label="Direct link to How Migrations Work in Nodestream" title="Direct link to How Migrations Work in Nodestream">​</a></h2>
<p>In nodestream, migrations are defined as a series of yaml files that describe the changes that need to be made to the schema.
Each migration file contains a list of operations that need to be performed.
For example, creating a new node type or adding a property to an existing node type.</p>
<p>When you run <code>nodestream migrations make</code> nodestream will create a new migration file in the <code>migrations</code> directory.
That process works roughly like this:</p>
<ul>
<li>Nodestream will look at the current state of the schema by initializing and introspecting all pipelines (A).</li>
<li>Build the state of the schema that is represented by the current migrations (B).</li>
<li>Diff the two states (A and B) to determine the changes that need to be made to the schema.</li>
<li>Generate a new migration file that describes the changes that need to be made to the schema.</li>
</ul>
<p>When you run <code>nodestream migrations run</code> nodestream will apply the migrations in sequence to evolve the schema.
That process works roughly like this:</p>
<ul>
<li>Nodestream reads the migration files into memory and builds a graph of the dependencies between the migrations.</li>
<li>Nodestream runs the migrations in topological order, applying the changes to the schema as it goes.</li>
<li>Nodestream keeps track of which migrations have been applied so that it can skip them in the future.</li>
</ul>
<p>Crucially, nodestream does not track all possible schema changes.
Topological changes are not tracked(see <a href="https://nodestream-proj.github.io/docs/blog/2024/05/14/migrations-evolution#topological-changes">here</a>), so you will need to handle those manually.
Additionally, nodestream does not support rolling back migrations, so you will need to handle that manually as well.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="are-migrations-any-good">Are Migrations Any Good?<a href="https://nodestream-proj.github.io/docs/blog/2024/05/14/migrations-evolution#are-migrations-any-good" class="hash-link" aria-label="Direct link to Are Migrations Any Good?" title="Direct link to Are Migrations Any Good?">​</a></h2>
<p>Wondering what Martin Fowler would think of this design given is <a href="https://martinfowler.com/articles/evodb.html" target="_blank" rel="noopener noreferrer">page on the subject</a>?
He describes the concept of "evolutionary database design" with a set of characterisitcs.
Some of them are more organizational than technical.</p>
<p>However, some of the technical ones are:</p>
<ul>
<li><strong>All Database Artifacts are Version Controlled with Application Code:</strong> Nodestream's migrations are intended to be source controlled files that are run in sequence and define their dependencies. This makes it easy to evolve changes and continuously integrate them (which is another of the characteristics).</li>
<li><strong>All database changes are database refactorings</strong> Nodestream's migrations are a series of database refactorings that are run in sequence. This makes it easy to track changes to the schema over time and to apply those changes to multiple environments, such as development, staging, and production. We are detecting the changes that need to be made to the schema and applying them in a controlled and repeatable way.</li>
<li><strong>Clearly Separate Database Access Code</strong> You generally don't need to write database access code in nodestream, so this is taken care of <!-- -->🎆</li>
<li><strong>Automated the Refactorings</strong> This is the main point of migrations. They are automated and can be run in sequence to evolve the schema.</li>
</ul>
<p>We are happy with the design of the migrations in nodestream and we think that they are a good fit for the project.
As we've mentioned, there are still some major evolutions to be made to migrations, such as the ability to rollback a migration, but we are confident that we are on the right track.</p>]]></content:encoded>
            <category>migrations</category>
            <category>nodestream</category>
        </item>
        <item>
            <title><![CDATA[Nodestream Neptune Support]]></title>
            <link>https://nodestream-proj.github.io/docs/blog/2024/04/26/nodestream-neptune-support</link>
            <guid>https://nodestream-proj.github.io/docs/blog/2024/04/26/nodestream-neptune-support</guid>
            <pubDate>Fri, 26 Apr 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[The recent release of Nodestream 0.12 has introduced support for Amazon Neptune as the first step towards broader multi-database support. Nodestream provides a flexible tool to perform bulk ETL into Amazon Neptune Database and Amazon Neptune Analytics.]]></description>
            <content:encoded><![CDATA[<p>The recent <a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-0-12/">release of Nodestream 0.12</a> has introduced support for Amazon Neptune as the first step towards broader multi-database support. Nodestream provides a flexible tool to perform bulk ETL into Amazon Neptune Database and Amazon Neptune Analytics.</p>
<p>This post will give a quick overview of the new Amazon Neptune support, offer some examples to get started, and list some features planned for future releases.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="overview">Overview<a href="https://nodestream-proj.github.io/docs/blog/2024/04/26/nodestream-neptune-support#overview" class="hash-link" aria-label="Direct link to Overview" title="Direct link to Overview">​</a></h2>
<p>Support for AWS Neptune is split into two modes, DB and Analytics. Both modes leverage the AWS SDK to load data via batched openCypher queries. Nodestream is compatible with Neptune DB engine version 1.2.1.1 or higher, as well as Neptune Analytics.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="capabilities">Capabilities<a href="https://nodestream-proj.github.io/docs/blog/2024/04/26/nodestream-neptune-support#capabilities" class="hash-link" aria-label="Direct link to Capabilities" title="Direct link to Capabilities">​</a></h2>
<p>Nodestream with Neptune currently supports standard ETL pipelines as well as time to live (TTL) pipelines. ETL pipelines enable bulk data ingestion into Neptune from a much broader range of data sources and formats than have previously been possible in Neptune.</p>
<p><a href="https://nodestream-proj.github.io/docs/docs/tutorials-intermediate/removing-data/">Nodestream's TTL mechanism</a> also enables new capabilities not previously available in Neptune. By annotating ingested graph elements with timestamps, Nodestream is able to create pipelines which automatically expire and remove data that has passed a configured lifespan.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="usage">Usage<a href="https://nodestream-proj.github.io/docs/blog/2024/04/26/nodestream-neptune-support#usage" class="hash-link" aria-label="Direct link to Usage" title="Direct link to Usage">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="prerequisites">Prerequisites<a href="https://nodestream-proj.github.io/docs/blog/2024/04/26/nodestream-neptune-support#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites">​</a></h3>
<p>Neptune must be reachable from whichever environment you intend to run Nodestream. Both Neptune Database, as well as Neptune Analytics with a private endpoint, are restricted to VPC-only access. If you intend to use a Neptune Analytics graph with a public endpoint, no special considerations are required.</p>
<p>Check out the <a href="https://docs.aws.amazon.com/neptune/latest/userguide/get-started-connecting.html" target="_blank" rel="noopener noreferrer">Neptune User-Guide</a> for more information about connecting to a VPC-only host. You can test the connection with this curl command:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">curl https://&lt;NEPTUNE_ENDPOINT&gt;:&lt;PORT&gt;/openCypher/status</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="iam-auth">IAM Auth<a href="https://nodestream-proj.github.io/docs/blog/2024/04/26/nodestream-neptune-support#iam-auth" class="hash-link" aria-label="Direct link to IAM Auth" title="Direct link to IAM Auth">​</a></h3>
<p>Nodestream fully supports IAM Authentication when connecting to Amazon Neptune, as long as credentials are properly configured. See the <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html#configuring-credentials" target="_blank" rel="noopener noreferrer">boto3 credentials guide</a> for more instruction on correctly configuring credentials.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="configuration-examples">Configuration Examples<a href="https://nodestream-proj.github.io/docs/blog/2024/04/26/nodestream-neptune-support#configuration-examples" class="hash-link" aria-label="Direct link to Configuration Examples" title="Direct link to Configuration Examples">​</a></h3>
<p>The connection configuration for Neptune contains a switch between two modes: <code>db</code> and <code>analytics</code>. Neptune DB mode will connect using a Neptune Database cluster or instance endpoint, while Neptune Analytics will connect via the graph identifier.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="neptune-database">Neptune Database:<a href="https://nodestream-proj.github.io/docs/blog/2024/04/26/nodestream-neptune-support#neptune-database" class="hash-link" aria-label="Direct link to Neptune Database:" title="Direct link to Neptune Database:">​</a></h4>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">targets</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">db-one</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">database</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> neptune</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">mode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> database</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">host</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> https</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">//&lt;NEPTUNE_ENDPOINT</span><span class="token punctuation" style="color:#393A34">&gt;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">&lt;PORT</span><span class="token punctuation" style="color:#393A34">&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="neptune-analytics">Neptune Analytics:<a href="https://nodestream-proj.github.io/docs/blog/2024/04/26/nodestream-neptune-support#neptune-analytics" class="hash-link" aria-label="Direct link to Neptune Analytics:" title="Direct link to Neptune Analytics:">​</a></h4>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">targets</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">db-one</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">database</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> neptune</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">mode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> analytics</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">graph_id</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> &lt;GRAPH_IDENTIFIER</span><span class="token punctuation" style="color:#393A34">&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Check out the <a href="https://nodestream-proj.github.io/docs/docs/category/tutorial---basics/">Nodestream basics tutorial</a> for a complete guide to getting started with Nodestream and Neptune.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="future-roadmap">Future Roadmap<a href="https://nodestream-proj.github.io/docs/blog/2024/04/26/nodestream-neptune-support#future-roadmap" class="hash-link" aria-label="Direct link to Future Roadmap" title="Direct link to Future Roadmap">​</a></h2>
<p>We have several new features planned to bring additional functionality in upcoming releases.</p>
<p>One feature we are excited to bring to the Nodestream Neptune plugin is support for the new Nodestream Migrations API. Some migrations are not applicable in Neptune as it does not use user-defined indices. However, support for applicable migrations, such as renaming properties, will be added in an upcoming release.</p>
<p>We are additionally planning to add expanded datatype support. Currently, the Neptune plugin supports string, boolean, and numeric types. Datetime types are automatically converted into epoch timestamps. We aim to expand this list such that any extracted types which are supported by Neptune can be loaded without casting or conversion.</p>
<p>Our future work will also include further performance assessments and optimizations. We will continue to optimize the generated queries in order to maximize the performance and scalability of Nodestream with Neptune.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="get-involved">Get Involved<a href="https://nodestream-proj.github.io/docs/blog/2024/04/26/nodestream-neptune-support#get-involved" class="hash-link" aria-label="Direct link to Get Involved" title="Direct link to Get Involved">​</a></h2>
<p>The inclusion of new features is heavily dependent on community feedback, if there are any additional features or configurations which you would find valuable, please create an issue on <a href="https://github.com/nodestream-proj/nodestream-plugin-neptune/issues" target="_blank" rel="noopener noreferrer">GitHub</a> with the request.</p>]]></content:encoded>
            <category>neptune</category>
            <category>nodestream</category>
        </item>
        <item>
            <title><![CDATA[Nodestream 0.12 Release]]></title>
            <link>https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-0-12</link>
            <guid>https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-0-12</guid>
            <pubDate>Fri, 05 Apr 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[We are happy to announce the release of Nodestream 0.12.]]></description>
            <content:encoded><![CDATA[<p>We are happy to announce the release of Nodestream 0.12.
This release marks the largest update to Nodestream since its inception.
We've spent a lot of time improving the core of nodestream and we're excited to share it with you.</p>
<p>Before we get into the details, we want to thank the community for their support and feedback.
As such, we have completely revamped the documentation to make it easier to use and navigate.
This releases comes with two headline features <a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-0-12#database-migrations">Database Migrations</a> and <a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-0-12#multi-database-support">Multi-Database Support</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="major-features">Major Features<a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-0-12#major-features" class="hash-link" aria-label="Direct link to Major Features" title="Direct link to Major Features">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="database-migrations">Database Migrations<a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-0-12#database-migrations" class="hash-link" aria-label="Direct link to Database Migrations" title="Direct link to Database Migrations">​</a></h3>
<p>In the past, nodestream attempted to automatically create indexes and constraints on the database based on your pipeline at runtime.
This was done by introspecting the schema of the entire project and generating the appropriate queries to create the indexes and constraints.
This was a very powerful feature but it had a few drawbacks:</p>
<ul>
<li><strong>It was redundant.</strong> The same indexes and constraints were being created with <code>IF NOT EXISTS</code> clauses every time the pipeline was run.</li>
<li><strong>It was slow.</strong> The queries were being executed serially and the pipeline was locked until they were all completed.</li>
<li><strong>It was error prone.</strong> If the database was not in a state that allowed for the creation of the indexes and constraints, the pipeline would fail.</li>
<li><strong>It was high friction.</strong> There was no way to refactor the database without manual intervention. If the schema changed, the pipeline would fail and the user would have to manually remove the indexes, constraints, and sometimes data before running the pipeline again.</li>
</ul>
<p>To address these issues, <code>nodestream</code> 0.12 has introduced the concept of migrations.
Migrations are a way of encapsulating changes to the database schema in a way that can be applied incrementally.
Conceptually, they are similar to the migrations in the <a href="https://docs.djangoproject.com/en/5.0/topics/migrations/" target="_blank" rel="noopener noreferrer">Django</a>, <a href="https://guides.rubyonrails.org/v3.2/migrations.html" target="_blank" rel="noopener noreferrer">Rails</a>, <a href="https://neo4j.com/labs/neo4j-migrations/2.0/" target="_blank" rel="noopener noreferrer">Neo4j Migrations</a>, and <a href="https://documentation.red-gate.com/fd/migrations-184127470.html" target="_blank" rel="noopener noreferrer">Flyway</a> frameworks.</p>
<p><img decoding="async" loading="lazy" alt="Database Migrations" src="https://nodestream-proj.github.io/docs/assets/images/migrations-1ede1ab3d5438cdca24d66cfa6d66231.gif" width="1800" height="600" class="img_ev3q"></p>
<p>Migrations are defined in a directory called <code>migrations</code> in the root of your project.
Each migration is a yaml file that contains data about the migration and its dependencies.
You can create migrations by running the <code>nodestream migrations make</code> command.</p>
<p>Check out the changes to the tutorial on <a href="https://nodestream-proj.github.io/docs/docs/tutorial-basics/prepare-your-database/">Database Migrations</a> as well as the new tutorial on <a href="https://nodestream-proj.github.io/docs/docs/tutorials-intermediate/working-with-migrations/">Working With Migrations</a> to learn more.</p>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
<li><a href="https://github.com/grantleehoffman" target="_blank" rel="noopener noreferrer">Grant Hoffman</a></li>
<li><a href="https://github.com/yasonk" target="_blank" rel="noopener noreferrer">Yason Khaburzaniya</a></li>
<li><a href="https://github.com/ccloes" target="_blank" rel="noopener noreferrer">Chad Cloes</a></li>
<li><a href="https://github.com/angelosantos4" target="_blank" rel="noopener noreferrer">Angelo Santos</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="multi-database-support">Multi-Database Support<a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-0-12#multi-database-support" class="hash-link" aria-label="Direct link to Multi-Database Support" title="Direct link to Multi-Database Support">​</a></h3>
<p>Prior to this release, the only database that was supported was neo4j.
While this is a category leading database, the goal of nodestream is to be database agnostic and afford developer the ability to use the database or <em>databases</em> that best fits their needs.
As such, we are happy to announce that nodestream now supports <a href="https://aws.amazon.com/neptune/" target="_blank" rel="noopener noreferrer">Amazon Neptune</a> and <a href="https://docs.aws.amazon.com/neptune-analytics/latest/userguide/what-is-neptune-analytics.html" target="_blank" rel="noopener noreferrer">Amazon Neptune Analytics</a>.
TO accommodate that, we have moved the neo4j database connector into a separate package called <a href="https://pypi.org/project/nodestream-plugin-neo4j/" target="_blank" rel="noopener noreferrer">nodestream-plugin-neo4j</a> and added a new package called <a href="https://pypi.org/project/nodestream-plugin-neptune/" target="_blank" rel="noopener noreferrer">nodestream-plugin-neptune</a>.</p>
<p>Starting with this release, you use the <code>--database</code> flag to generate neptune boilerplate configuration.</p>
<p><img decoding="async" loading="lazy" alt="Database Migrations" src="https://nodestream-proj.github.io/docs/assets/images/neptune-2c1c78b173e824fc1e824f54287e467f.gif" width="1800" height="800" class="img_ev3q"></p>
<p><strong>Check out the docs on it <a href="https://nodestream-proj.github.io/docs/docs/databases/neptune/">here</a></strong>.</p>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
<li><a href="https://github.com/aryex" target="_blank" rel="noopener noreferrer">Alex Le</a></li>
<li><a href="https://github.com/Cole-Greer" target="_blank" rel="noopener noreferrer">Cole Greer</a></li>
<li><a href="https://github.com/bechbd" target="_blank" rel="noopener noreferrer">Dave Bechberger</a></li>
<li><a href="https://github.com/alexey-temnikov" target="_blank" rel="noopener noreferrer">Alexey Temnikov</a></li>
<li><a href="https://github.com/xiazcy" target="_blank" rel="noopener noreferrer">Yang Xia</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="other-features">Other Features<a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-0-12#other-features" class="hash-link" aria-label="Direct link to Other Features" title="Direct link to Other Features">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="parquet-support">Parquet Support<a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-0-12#parquet-support" class="hash-link" aria-label="Direct link to Parquet Support" title="Direct link to Parquet Support">​</a></h3>
<p>Many customers have data stored in parquet format.
Parquet is a columnar storage format that is optimized for reading and writing large datasets.
We are happy to announce that nodestream now supports parquet as a first class citizen.</p>
<p><strong>Check out the docs on it <a href="https://nodestream-proj.github.io/docs/docs/reference/extractors/#the-file-extractor">here</a></strong>.</p>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
<li><a href="https://github.com/bechbd" target="_blank" rel="noopener noreferrer">Dave Bechberger</a></li>
<li><a href="https://github.com/Cole-Greer" target="_blank" rel="noopener noreferrer">Cole Greer</a></li>
<li><a href="https://github.com/leszek-bq" target="_blank" rel="noopener noreferrer">Leszek Kurzyna</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="include-properties-from-maps">Include Properties From Maps<a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-0-12#include-properties-from-maps" class="hash-link" aria-label="Direct link to Include Properties From Maps" title="Direct link to Include Properties From Maps">​</a></h3>
<p>In the past, each property you wanted to include in the pipeline had to be explicitly defined in the pipeline configuration.
This was a bit cumbersome and error prone.
Starting with this release, you can now include all properties by defining an expression that returns a map at the <code>properties</code> key directly instead of a mapping of property names to expressions.</p>
<p>For example, here are two examples on the <code>properties</code> and <code>source_node</code> interpretations:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> source_node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">node_type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> User</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">email</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token tag" style="color:#00009f">!jmespath</span><span class="token plain"> email</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">properties</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token tag" style="color:#00009f">!jmespath</span><span class="token plain"> path.to.properties.mapping</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">normalization</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">do_trim_whitespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> properties</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">properties</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token tag" style="color:#00009f">!jmespath</span><span class="token plain"> path.to.properties.mapping</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">normalization</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">do_lowercase_strings</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Check out the docs on it <a href="https://nodestream-proj.github.io/docs/docs/reference/interpreting/">here</a></strong>.</p>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
<li><a href="https://github.com/bechbd" target="_blank" rel="noopener noreferrer">Dave Bechberger</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="performance-improvements">Performance Improvements<a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-0-12#performance-improvements" class="hash-link" aria-label="Direct link to Performance Improvements" title="Direct link to Performance Improvements">​</a></h3>
<p>We've made a small number of performance improvements to the core of nodestream that should result in faster processing times and lower memory usage.
Most notably, we've cache the <code>last_ingested_at</code> timestamp for nodes and relationships to reduce the number of times we create objects in memory.
We've observed a 10% improvement in processing times and a 5% reduction in memory usage in our testing.</p>
<p>Core Contributors to this feature include:</p>
<ul>
<li><a href="https://github.com/zprobst" target="_blank" rel="noopener noreferrer">Zach Probst</a></li>
<li><a href="https://github.com/yasonk" target="_blank" rel="noopener noreferrer">Yason Khaburzaniya</a></li>
<li><a href="https://github.com/grantleehoffman" target="_blank" rel="noopener noreferrer">Grant Hoffman</a></li>
</ul>]]></content:encoded>
            <category>release</category>
            <category>nodestream</category>
        </item>
        <item>
            <title><![CDATA[Software Vulnerability Analysis using SBOMs, Amazon Neptune, and Nodestream]]></title>
            <link>https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-sbom-preview</link>
            <guid>https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-sbom-preview</guid>
            <pubDate>Fri, 05 Apr 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[Note: Both the Nodestream Neptune and Nodestream SBOM plugins are currently preview releases]]></description>
            <content:encoded><![CDATA[<p><strong>Note</strong>: Both the Nodestream Neptune and Nodestream SBOM plugins are currently preview releases</p>
<p>Recently, (March 2024) <a href="https://www.cisecurity.org/advisory/a-vulnerability-in-xz-utils-could-allow-for-remote-code-execution_2024-033" target="_blank" rel="noopener noreferrer">a severe vulnerability was found to have been added to a common library, XZ utility</a>. Unfortunately, serious software vulnerabilities are not isolated incidents, as in late 2021, a <a href="https://www.ncsc.gov.uk/information/log4j-vulnerability-what-everyone-needs-to-know" target="_blank" rel="noopener noreferrer">critical security vulnerability was discovered in a commonly used logging library, Log4j</a>. While the origin of the issues differ, Log4j was an oversight while XZ was an explicit backdoor, the outcome for users was the end same. Once each vulnerability was known, companies and individuals spent many hours combing through countless applications, looking for and patching systems running vulnerable versions of the software.</p>
<p>As this effort was ongoing, many were asking, "Isn't there a better way to track this information?"</p>
<p>In this post, we will discuss the work we have been doing around creating a plugin for Nodestream that provides a unified graph model for SBOMs ingestion and analysis. We will combine this with the plugin for Amazon Neptune to demonstrate how you can find insights for software vulnerabilities in application stacks. Let’s first talk a bit about what an SBOM is and why you should use a graph for analysis.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-a-software-bill-of-materials-sbom-and-why-use-graphs">What is a Software Bill of Materials (SBOM) and why use Graphs<a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-sbom-preview#what-is-a-software-bill-of-materials-sbom-and-why-use-graphs" class="hash-link" aria-label="Direct link to What is a Software Bill of Materials (SBOM) and why use Graphs" title="Direct link to What is a Software Bill of Materials (SBOM) and why use Graphs">​</a></h2>
<p>A software bill of materials (SBOM) is a critical component of software development and management, helping organizations to improve the transparency, security, and reliability of their software applications. An SBOM acts as an "ingredient list" of libraries and components of a software application that:</p>
<ul>
<li>Enables software creators to track dependencies within their applications</li>
<li>Provides security personnel the ability to examine and assess the risk of potential vulnerabilities within an environment</li>
<li>Provides legal personnel with the information needed to assure that a particular software is in compliance with all licensing requirements.</li>
</ul>
<p>A software bill of materials (SBOM) is a comprehensive list of the components, libraries, and dependencies used in a software application or system. It provides a detailed breakdown of the software's architecture, including the names, versions, licenses, and optionally the vulnerabilities of each component and describes the complex dependencies and relationships between components of a software system, including multi-level hierarchies and recursive relationships.</p>
<p>Graphs are excellent for modeling these kinds of interconnected relationships, with nodes representing components and edges representing dependencies and relationships between these components. Graph data structures handle recursive relationships very naturally, making it easy to analyze networks and flows. Using graph algorithms and metrics, allows you to analyze and identify critical components and dependencies, single points of failure, security vulnerabilities, license compatibilities, etc. for use cases such as:</p>
<ul>
<li>Dependency graphs - These show how different components in the software relate to and depend on each other. Graphs make these complex relationships easier to visualize.</li>
<li>Vulnerability Graphs - Graphs make it easy to determine and assign associated risks with different vulnerabilities to prioritize fixing known issues.</li>
<li>Supply chain graphs - SBOMs trace the components and dependencies up the software supply chain. Graphs can illustrate the flow of open-source components from lower-level suppliers up to the final product. This helps identify vulnerabilities or licensing issues in the supply chain.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-use-graphs-for-sbom-analysis">How to use Graphs for SBOM analysis<a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-sbom-preview#how-to-use-graphs-for-sbom-analysis" class="hash-link" aria-label="Direct link to How to use Graphs for SBOM analysis" title="Direct link to How to use Graphs for SBOM analysis">​</a></h2>
<p>While using graphs to assist with SBOM analysis is not new, it also has not been trivial to get the data loaded in due to differing formats, with the two most popular being <a href="https://cyclonedx.org/" target="_blank" rel="noopener noreferrer">CycloneDX</a> and <a href="https://spdx.dev/" target="_blank" rel="noopener noreferrer">SPDX</a>. To assist with the data loading and analysis, I recently worked on an <a href="https://github.com/nodestream-proj/nodestream-plugin-sbom/tree/main" target="_blank" rel="noopener noreferrer">SBOM plugin</a> for <a href="https://nodestream-proj.github.io/docs/docs/intro/" target="_blank" rel="noopener noreferrer">Nodestream</a> to provide a simple way to load SBOMs into an opinionated graph data model from local files, GitHub, or Amazon Inspector. <a href="https://nodestream-proj.github.io/docs/docs/intro/" target="_blank" rel="noopener noreferrer">Nodestream</a> is a Python framework for performing graph database ETL. The SBOM plugin extends this framework to provide a</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="loading-data-into-sboms-into-our-graph">Loading Data into SBOMs into our Graph<a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-sbom-preview#loading-data-into-sboms-into-our-graph" class="hash-link" aria-label="Direct link to Loading Data into SBOMs into our Graph" title="Direct link to Loading Data into SBOMs into our Graph">​</a></h3>
<p>To get started loading your SBOM files into Amazon Neptune, we first need to setup an Amazon Neptune Analytics Graph as well as a Neptune Notebook to perform our analysis. To configure a Neptune Analytics Graph you can follow the documentation here: <a href="https://docs.aws.amazon.com/neptune-analytics/latest/userguide/create-graph-using-console.html" target="_blank" rel="noopener noreferrer">https://docs.aws.amazon.com/neptune-analytics/latest/userguide/create-graph-using-console.html</a></p>
<p>Neptune Notebooks is a managed open-source graph-notebook project provides a plethora of Jupyter extensions and sample notebooks that make it easy to interact with and learn to use a Neptune Analytics graph. This can be configured using the documentation here: <a href="https://docs.aws.amazon.com/neptune-analytics/latest/userguide/notebooks.html" target="_blank" rel="noopener noreferrer">https://docs.aws.amazon.com/neptune-analytics/latest/userguide/notebooks.html</a></p>
<p>Now that we have setup our database and analysis environment we next need to install the Nodestream plugins for Neptune and SBOM.</p>
<p><code>pip install -q pyyaml nodestream-plugin-neptune nodestream-plugin-sbom</code></p>
<p>With those data files installed, all we need to do is set our configuration in the <code>nodestream.yaml</code> file as shown below. In this example, we are going to load the SBOM files for Nodestream, the Nodestream Neptune Plugin, and the Nodestream SBOM plugin into our database, directly from GitHub.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">plugins:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- name: sbom</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  config:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    repos:[nodestream-proj/nodestream, nodestream-proj/nodestream-plugin-sbom, nodestream-proj/nodestream-plugin-neptune]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">targets:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  my-neptune:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    database: neptune</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    graph_id: g-&lt;GRAPH ID&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mode: analytics</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>With our configuration setup, we can run the import using the following command:</p>
<p><code>nodestream run sbom_github --target my-neptune</code></p>
<p>After we run the data load, we get a graph that similar to the image below.</p>
<p><img decoding="async" loading="lazy" alt="SBOM Model Overview" src="https://nodestream-proj.github.io/docs/assets/images/sbom_overview-11f78470eba485ca6b53f6be5c6c0cc6.png" title="SBOM Data Overview" width="1422" height="1324" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-does-our-graph-look-like">What does our graph look like?<a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-sbom-preview#what-does-our-graph-look-like" class="hash-link" aria-label="Direct link to What does our graph look like?" title="Direct link to What does our graph look like?">​</a></h3>
<p>Let’s take a look at the types of data that we are storing in our graph. The plugin uses the opinionated graph data model shown below to represent SBOM data files.
<img decoding="async" loading="lazy" alt="SBOM Graph schema" src="https://nodestream-proj.github.io/docs/assets/images/schema-060f6f9a4f1036b5c1af339fd68d47fe.png" title="SBOM Graph Schema" width="581" height="481" class="img_ev3q">
This model contains the following elements:</p>
<p><strong>Node Types</strong></p>
<ul>
<li><code>Document</code> - This represents the SBOM document as well as the metadata associated with that SBOM.</li>
<li><code>Component</code> - This represents a specific component of a software system.</li>
<li><code>Reference</code> - This represents a reference to any external system which the system wanted to include as a reference. This can range from package managers, URLs to external websites, etc.</li>
<li><code>Vulnerability</code> - This represents a specific known vulnerability for a component.</li>
<li><code>License</code> - The license for the component or package.</li>
</ul>
<p><strong>Edge Types</strong></p>
<ul>
<li><code>DESCRIBES</code>/<code>DEPENDS_ON</code>/<code>DEPENDENCY_OF</code>/<code>DESCRIBED_BY</code>/<code>CONTAINS</code> - This represents the type of relationship between a <code>Document</code> and a <code>Component</code> in the system.</li>
<li><code>REFERS_TO</code> - This represents a reference between a <code>Component</code> and a <code>Reference</code></li>
<li><code>AFFECTS</code> - This represents that a particular <code>Component</code> is affected by the connected <code>Vulnerability</code></li>
</ul>
<p>The properties associated with each element will vary depending on the input format used, and the optional information contained in each file.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="analyzing-sboms">Analyzing SBOMs<a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-sbom-preview#analyzing-sboms" class="hash-link" aria-label="Direct link to Analyzing SBOMs" title="Direct link to Analyzing SBOMs">​</a></h2>
<p>Now that we have our data loaded into our graph, the next step is to start to extract insights into what is actually important in our SBOM data.</p>
<p>One common use case is to investigate shared dependencies across projects. Shared dependencies allow development and security teams to better understand the security posture of the organization through identification of shared risks. Let's start by taking a look at the most shared dependencies between these projects using the query below.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">MATCH (n:Component)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WHERE exists(n.name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">CALL neptune.algo.degree(n, {traversalDirection: 'inbound', edgeLabels: ['DEPENDS_ON']})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">YIELD node, degree</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">RETURN node.name, degree</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ORDER BY degree DESC</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LIMIT 10</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Running this query will show us that there are quite a few dependencies that are shared across all three projects. To do this analysis, we used a graph algorithm known as <a href="https://docs.aws.amazon.com/neptune-analytics/latest/userguide/degree.html" target="_blank" rel="noopener noreferrer">Degree Centrality</a> which counts the number of edges connected to a node. This measure of how connected the node is can in turn indicate the node's importance and level of influence in the network.
<img decoding="async" loading="lazy" alt="Results" src="https://nodestream-proj.github.io/docs/assets/images/analyze_query_1-caba0b29d04a259615e94657bad62d68.png" title="Results" width="899" height="359" class="img_ev3q">
Running the query below shows us that there are 31 <code>Components</code> that are shared across all the projects.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">MATCH (n:Component)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WHERE exists(n.name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">CALL neptune.algo.degree(n, {traversalDirection: 'inbound', edgeLabels: ['DEPENDS_ON']})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">YIELD node, degree</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WHERE degree=3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">RETURN count(node)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Given that this is a closely connected group of projects, it is not a surprise that there are many shared components. Given that one of the strengths of graphs is the ability to visualize the connectedness between data, let’s take a look at how they are connected.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">MATCH (n:Component)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WHERE exists(n.name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">CALL neptune.algo.degree(n, {traversalDirection: 'inbound', edgeLabels: ['DEPENDS_ON']})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">YIELD node, degree</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WHERE degree = 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WITH node, degree</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">MATCH p=(node)-[]-()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">RETURN p</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="Results" src="https://nodestream-proj.github.io/docs/assets/images/analyze_query_2-1f39a8b8627249ee7c26b96efd2b5423.png" title="Results" width="1154" height="1107" class="img_ev3q"></p>
<p>Another common use case is to investigate licensing across multiple projects. This sort of investigation benefits from the connectedness across the graph by leveraging the connectedness to find how component licenses are connected to each other. Let’s take a look at what other licenses are associated with the <code>lgpl-2.1-or-later</code> licensed components.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">MATCH p=(l:License)&lt;-[:LICENSED_BY]-(:Component)&lt;-[:DEPENDS_ON]-(:Document)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-[:DEPENDS_ON]-&gt;(:Component)-[:LICENSED_BY]-&gt;(l2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WHERE l.name = 'lgpl-2.1-or-later' and l&lt;&gt;l2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">RETURN DISTINCT l2.name</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="Results" src="https://nodestream-proj.github.io/docs/assets/images/analyze_query_3-251a3b3cceab1a4c22d933c067766035.png" title="Results" width="908" height="456" class="img_ev3q"></p>
<p>As we see, there are quite a few other licenses used in these projects. We can leverage the visual nature of graph results to gain some insight into how components are connected. In this case, let’s see how components with the <code>lgpl-2.1-or-later</code> are connected to components with the <code>unlicense</code>.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">MATCH p=(l:License)←[:LICENSED_BY]-(:Component)←[:DEPENDS_ON]-(:Document)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-[:DEPENDS_ON]→(:Component)-[:LICENSED_BY]→(l2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WHERE l.name = 'lgpl-2.1-or-later' and l&lt;&gt;l2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">RETURN DISTINCT l2.name</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="Results" src="https://nodestream-proj.github.io/docs/assets/images/analyze_query_4-f60d2400b6913194c5ed7fde6d7abc34.png" title="Results" width="565" height="425" class="img_ev3q"></p>
<p>We see that there exists one path in our graph between these two licenses.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="next-steps">Next Steps<a href="https://nodestream-proj.github.io/docs/blog/2024/04/05/nodestream-sbom-preview#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps">​</a></h2>
<p>As we have seen, using graphs to perform analysis of SBOM data can be a powerful tool in your toolbox to gain insights into the connections between software projects. What I have shown here is only the beginning of the types of analysis you can perform with this data. For a more detailed walkthrough of using graphs for SBOM analysis, I recommend taking a look at the following notebooks:</p>
<ul>
<li>
<p><a href="https://github.com/aws/graph-notebook/blob/main/src/graph_notebook/notebooks/02-Neptune-Analytics/03-Sample-Use-Cases/03-Software-Bill-Of-Materials/01-SBOM-Dependency-Analysis.ipynb" target="_blank" rel="noopener noreferrer">SBOM Dependency Analysis</a></p>
</li>
<li>
<p><a href="https://github.com/aws/graph-notebook/blob/main/src/graph_notebook/notebooks/02-Neptune-Analytics/03-Sample-Use-Cases/03-Software-Bill-Of-Materials/02-SBOM-Vulnerability-Analysis.ipynb" target="_blank" rel="noopener noreferrer">SBOM Vulnerability Analysis</a></p>
</li>
</ul>]]></content:encoded>
            <category>sbom</category>
            <category>nodestream</category>
        </item>
        <item>
            <title><![CDATA[Welcome]]></title>
            <link>https://nodestream-proj.github.io/docs/blog/welcome</link>
            <guid>https://nodestream-proj.github.io/docs/blog/welcome</guid>
            <pubDate>Sat, 30 Mar 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[Welcome to the new nodestream documentation and project site!]]></description>
            <content:encoded><![CDATA[<p>Welcome to the new nodestream documentation and project site!
We are excited to share with you the new features and improvements we have been working on.</p>
<p>We have been working hard to improve the documentation and make it easier to use and navigate.
We have also been working on improving the project site to make it easier to find the information you need.</p>
<p>We hope you find the new documentation and project site helpful and easy to use!</p>
<p>By the way, thanks to the <a href="https://docusaurus.io/" target="_blank" rel="noopener noreferrer">Docusaurus</a> team for creating such a great tool!</p>
<p>If you have any questions or feedback, please feel free to reach out to us on <a href="https://github.com/nodestream-proj/nodestream" target="_blank" rel="noopener noreferrer">GitHub</a>!</p>]]></content:encoded>
            <category>welcome</category>
            <category>nodestream</category>
        </item>
    </channel>
</rss>