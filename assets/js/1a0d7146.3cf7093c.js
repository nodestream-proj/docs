"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8855],{6799:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>r,default:()=>p,frontMatter:()=>a,metadata:()=>s,toc:()=>l});var o=n(4848),i=n(8453);const a={sidebar_position:3},r="Create A New Pipeline",s={id:"tutorial-basics/create-a-new-pipeline",title:"Create A New Pipeline",description:"Let's build an org chart with Nodestream.",source:"@site/docs/tutorial-basics/create-a-new-pipeline.md",sourceDirName:"tutorial-basics",slug:"/tutorial-basics/create-a-new-pipeline",permalink:"/docs/docs/tutorial-basics/create-a-new-pipeline",draft:!1,unlisted:!1,editUrl:"https://github.com/nodesteram-proj/docs/tree/main/packages/create-docusaurus/templates/shared/docs/tutorial-basics/create-a-new-pipeline.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Managing Your Project",permalink:"/docs/docs/tutorial-basics/managing-your-project"},next:{title:"Prepare Your Database",permalink:"/docs/docs/tutorial-basics/prepare-your-database"}},d={},l=[{value:"Describing the Data Model",id:"describing-the-data-model",level:2},{value:"Loading Data File",id:"loading-data-file",level:2},{value:"Interpteting Data Into Nodes and Relationships",id:"interpteting-data-into-nodes-and-relationships",level:2},{value:"Source Node Interpretation",id:"source-node-interpretation",level:3},{value:"Relationship Interpretation",id:"relationship-interpretation",level:3},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",mdxAdmonitionTitle:"mdxAdmonitionTitle",mermaid:"mermaid",p:"p",pre:"pre",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.h1,{id:"create-a-new-pipeline",children:"Create A New Pipeline"}),"\n",(0,o.jsx)(t.p,{children:"Let's build an org chart with Nodestream."}),"\n",(0,o.jsx)(t.p,{children:"In this tutorial, we'll walk you through creating a new pipeline in your Nodestream project."}),"\n",(0,o.jsx)(t.h2,{id:"describing-the-data-model",children:"Describing the Data Model"}),"\n",(0,o.jsx)(t.p,{children:"The first step in creating a new pipeline is to describe the data model that you want to load into your database.\nNodestream uses a simple YAML format to describe the data model - so we don't need to write any code to get started.\nIn this example, we're going to create an org chart for a fictional company by loading data from a CSV file."}),"\n",(0,o.jsx)(t.p,{children:"Here's an example of what the data model might look like:"}),"\n",(0,o.jsx)(t.mermaid,{value:"graph TD\n  A[Employee] --\x3e|reports to| B[Employee]\n  B --\x3e|reports to| C[Employee]\n  C --\x3e|reports to| D[Employee]\n  E[Employee] --\x3e|reports to| C\n  F[Employee] --\x3e|reports to| D\n  G[Employee] --\x3e|reports to| B"}),"\n",(0,o.jsx)(t.h2,{id:"loading-data-file",children:"Loading Data File"}),"\n",(0,o.jsx)(t.p,{children:"Before we can load the data into our database, we need to load the data from a file and interpret it into nodes and relationships.\nIn this example, we're going to load the data from a CSV file that looks like this:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-csv",children:"employee_id,employee_name,manager_id\n1,Alice,\n2,Bob,1\n3,Charlie,1\n4,David,2\n5,Eve,2\n6,Frank,3\n7,Grace,3\n"})}),"\n",(0,o.jsxs)(t.p,{children:["Copy the data into a file called ",(0,o.jsx)(t.code,{children:"employees.csv"})," in a newly created ",(0,o.jsx)(t.code,{children:"data"})," directory of your project."]}),"\n",(0,o.jsxs)(t.p,{children:["Now, open the ",(0,o.jsx)(t.code,{children:"pipelines/org-chart.yaml"})," file in your project that you created in the previous step.\nAs a reminder, the file should look like this:"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",children:"- arguments:\n    stop: 100000\n  factory: range\n  implementation: nodestream.pipeline:IterableExtractor\n- arguments:\n    interpretations:\n    - key:\n        number: !jmespath 'index'\n      node_type: Number\n      type: source_node\n  implementation: nodestream.interpreting:Interpreter\n"})}),"\n",(0,o.jsx)(t.p,{children:"Every pipeline is a list of steps that describe how to load the data into your database.\nThe first section in the pipeline is to extract the data from the file."}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",children:"- arguments:\n    stop: 100000\n  factory: range\n  implementation: nodestream.pipeline:IterableExtractor\n"})}),"\n",(0,o.jsx)(t.p,{children:"The second section is to interpret the data into nodes and relationships."}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",children:"- arguments:\n    interpretations:\n    - key:\n        number: !jmespath 'index'\n      node_type: Number\n      type: source_node\n  implementation: nodestream.interpreting:Interpreter\n"})}),"\n",(0,o.jsx)(t.p,{children:"For now, leave the second section as it is and replace the first section with the following:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",children:"- implementation: nodestream.pipeline.extractors:FileExtractor\n  arguments:\n    globs:\n      - data/*.csv\n"})}),"\n",(0,o.jsxs)(t.p,{children:["This step uses the ",(0,o.jsx)(t.code,{children:"FileExtractor"})," to load the data from the ",(0,o.jsx)(t.code,{children:"data"})," directory in your project.\nSpeicifically, nodestream is initializing the ",(0,o.jsx)(t.code,{children:"FileExtractor"})," class in the ",(0,o.jsx)(t.code,{children:"nodestream.pipeline.extractors"})," module.\nThe ",(0,o.jsx)(t.code,{children:"FileExtractor"})," expects a list of glob strings passed as an argument in the ",(0,o.jsx)(t.code,{children:"arugments"})," section representing the files to load.\nEvery file that matches these glob strings is loaded and its contents are passed to the next step in the pipeline.\nCSV files are supported by default and yield each row of the csv file as a dictionary to the next step in the pipeline."]}),"\n",(0,o.jsxs)(t.admonition,{type:"note",children:[(0,o.jsx)(t.mdxAdmonitionTitle,{}),(0,o.jsxs)(t.p,{children:["You are NOT limited to CSV files. Nodestream has many extractors that can load data from a variety of sources. Read more about ",(0,o.jsx)(t.a,{href:"../../reference/extractors",children:"extractors"})," in the documentation."]})]}),"\n",(0,o.jsx)(t.h2,{id:"interpteting-data-into-nodes-and-relationships",children:"Interpteting Data Into Nodes and Relationships"}),"\n",(0,o.jsxs)(t.p,{children:["The next step in the pipeline is to interpret the data into nodes and relationships.\nIn this example, we want to interpret the data into ",(0,o.jsx)(t.code,{children:"Employee"})," nodes and ",(0,o.jsx)(t.code,{children:"reports to"})," relationships.\nTo do this, we need to update the second section in the pipeline to look like this:"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",children:"- implementation: nodestream.interpreting:Interpreter\n  arguments:\n    interpretations:\n    - type: source_node\n      key:\n        employee_id: !jmespath 'employee_id'\n      properties:\n        name: !jmespath 'employee_name'\n      node_type: Employee\n    - type: relationship\n      node_type: Employee\n      relationship_type: REPORTS_TO\n      node_key:\n        employee_id: !jmespath 'manager_id'\n"})}),"\n",(0,o.jsxs)(t.p,{children:["The next section you will spend the most time with is the ",(0,o.jsx)(t.code,{children:"Interpreter"})," step.\nThe ",(0,o.jsx)(t.code,{children:"Interpreter"})," step is responsible for interpreting the data into nodes and relationships.\nThe ",(0,o.jsx)(t.code,{children:"Interpreter"})," step expects a list of interpretations passed as an argument in the ",(0,o.jsx)(t.code,{children:"arguments"})," section.\nEach interpretation is a dictionary that describes how to interpret the data into nodes and relationships.\nIn the following example, we will explain the two interpretations from when we updated the second section."]}),"\n",(0,o.jsx)(t.h3,{id:"source-node-interpretation",children:"Source Node Interpretation"}),"\n",(0,o.jsxs)(t.p,{children:["The following section is the first interpretation, which is a ",(0,o.jsx)(t.code,{children:"source_node"})," interpretation.\nIt describes how to interpret the data into ",(0,o.jsx)(t.code,{children:"Employee"})," nodes."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",children:"- type: source_node\n  key:\n    employee_id: !jmespath 'employee_id'\n  properties:\n    name: !jmespath 'employee_name'\n  node_type: Employee\n"})}),"\n",(0,o.jsxs)(t.p,{children:["A source node represents the node at the conceptual \"center\" of the ingest.\nTypically, this represents the central entity that you are modeling with the ingest.\nIn our case, it's the employee for whom the record represents.\nWe've decided to call this type of node an ",(0,o.jsx)(t.code,{children:"Employee"}),"."]}),"\n",(0,o.jsxs)(t.p,{children:["The ",(0,o.jsx)(t.code,{children:"key"})," block tells nodestream what set of properties represents a unique node of the ",(0,o.jsx)(t.code,{children:"node_type"})," and how to get the values.\nIn our case, we use the employee_id field the record and extract that using the !jmespath Value Provider."]}),"\n",(0,o.jsxs)(t.p,{children:["We take a similar approach with the properties field. We extract the ",(0,o.jsx)(t.code,{children:"name"})," property.\nNote that we have kept the field names on the node the same as the CSV document, but this does not need to be the case."]}),"\n",(0,o.jsxs)(t.p,{children:["See Also: ",(0,o.jsx)(t.a,{href:"/docs/docs/reference/interpreting#source-node-interpretation",children:"Reference documentation for source node interpretation"})]}),"\n",(0,o.jsx)(t.h3,{id:"relationship-interpretation",children:"Relationship Interpretation"}),"\n",(0,o.jsx)(t.p,{children:"A graph database would be a lot less useful if we did not create relationships to other data.\nIn our case, we want to model the org chart, so the following section draws the relationship to the employee's boss."}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",children:"- type: relationship\n  node_type: Employee\n  relationship_type: REPORTS_TO\n  node_key:\n    employee_id: !jmespath 'manager_id'\n"})}),"\n",(0,o.jsxs)(t.p,{children:["Here we tell the interpreter that we want to relate to an ",(0,o.jsx)(t.code,{children:"Employee"})," to our source node with a relationship type of ",(0,o.jsx)(t.code,{children:"REPORTS_TO"}),".\nFor nodestream to know which ",(0,o.jsx)(t.code,{children:"Employee"})," node to relate to, we need to specify the key of the related node.\nIn our case, we can do that by extracting the value of ",(0,o.jsx)(t.code,{children:"manager_id"})," and mapping it to the ",(0,o.jsx)(t.code,{children:"employee_id"})," key of the related node."]}),"\n",(0,o.jsxs)(t.p,{children:["See Also: ",(0,o.jsx)(t.a,{href:"/docs/docs/reference/interpreting#relationship-interpretation",children:"Reference documentation for relationship interpretation"})]}),"\n",(0,o.jsx)(t.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsxs)(t.p,{children:["Now that you've created a new pipeline, you can ",(0,o.jsx)(t.a,{href:"/docs/docs/tutorial-basics/prepare-your-database",children:"prepare your database"})," to load the data into your database."]})]})}function p(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>s});var o=n(6540);const i={},a=o.createContext(i);function r(e){const t=o.useContext(a);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),o.createElement(a.Provider,{value:t},e.children)}}}]);